{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a02b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/denis/code/Word2Vec\")\n",
    "from CBOW import CBOW\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from sklearn.decomposition import PCA\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5b80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "f = open('voina_i_mir.txt','r')\n",
    "text = f.read()\n",
    "f.close()\n",
    "text = CBOW.tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ea206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_embeddings(embeddings, labels, word, path):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.title(f\"{len(labels)} ближайших слов к слову: {word}\")\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.savefig(f\"{path}/words/{word}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc58692",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20\n",
    "tsne = PCA(n_components=2)\n",
    "words = [\n",
    "    \"война\", \"мир\", \"любовь\", \"аристократия\", \"судьба\", \"героизм\", \"семья\", \"честь\", \"дружба\",\n",
    "    \"революция\", \"Россия\", \"Наполеон\", \"брак\", \"измена\", \"жертва\", \"дуб\", \"небо\",\n",
    "    \"Пьер\", \"Безухов\", \"Наташа\", \"Ростов\", \"Андрей\", \"Болконский\", \"Николай\", \"Марья\", \"Курагин\", \"Москва\",\n",
    "    \"поле\", \"имение\", \"Лев\", \"Толстой\", \"Бонапарт\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f29f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBOW(text, embedding_size=100, windows_size=10, lr=1e-2, num_epochs=1, batch_size=10000, device='cuda', num_workers=os.cpu_count(), log=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13837e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21048, 289060)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab), len(model.vocab.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a7e187",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"train\"):\n",
    "    os.mkdir(\"train\")\n",
    "with open('train/result.csv', 'a') as file:\n",
    "    file.write('word,embedding,window_size,embedding_size,word1,word2,word3,word4,word5,word6,word7,word8,word9,word10,word11,word12,word13,word14,word15,word16,word17,word18,word19,word20\\n')\n",
    "for windows_size in range(1, 102, 20):\n",
    "    if not os.path.isdir(f\"train/ws{windows_size}\"):\n",
    "        os.mkdir(f\"train/ws{windows_size}\")\n",
    "    for i, embedding_size in enumerate(range(10, 311, 50)):\n",
    "        if not os.path.isdir(f\"train/ws{windows_size}/emb{embedding_size}\"):\n",
    "            os.mkdir(f\"train/ws{windows_size}/emb{embedding_size}\")\n",
    "        if not os.path.isdir(f\"train/ws{windows_size}/emb{embedding_size}/words\"):\n",
    "            os.mkdir(f\"train/ws{windows_size}/emb{embedding_size}/words\")\n",
    "        model = CBOW(text, embedding_size=embedding_size, windows_size=windows_size, lr=1e-2, num_epochs=35, batch_size=8000 - i * 900, device='cuda', num_workers=os.cpu_count(), log=f\"train/ws{windows_size}/emb{embedding_size}\")\n",
    "        for word in words:\n",
    "            k_word, embed = model.euclid_dist(word, vocab_size)\n",
    "            embeddings_2d = tsne.fit_transform(embed.tolist())\n",
    "            with open('train/result.csv', 'a') as file:\n",
    "                file.write(f\"{word},{model[word].tolist()},{windows_size},{embedding_size},\" + \",\".join(k_word)+\"\\n\")\n",
    "            plot_embeddings(embeddings_2d, k_word, word, f\"train/ws{windows_size}/emb{embedding_size}\")\n",
    "        del model\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
